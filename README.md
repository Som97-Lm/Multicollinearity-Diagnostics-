# Multicollinearity Diagnostics Notebook

This repository contains a focused notebook demonstrating how to detect and handle **multicollinearity** in regression datasets.  
Multicollinearity occurs when predictor variables are highly correlated, leading to unstable coefficient estimates and unreliable models.  
This notebook provides practical techniques to identify, measure, and address this issue.

---

##  Notebook Included
- **multicolinearity_1.ipynb**

This notebook covers:
- Variance Inflation Factor (VIF) calculation  
- Correlation matrix interpretation  
- Detecting redundant features  
- Identifying problematic predictors  
- Strategies for resolving multicollinearity:
  - Feature removal  
  - Combining correlated variables  
  - Regularization (Lasso / Ridge context explanation)

---

## Objective
To provide a clear, hands-on demonstration of:
- What multicollinearity is  
- Why it creates problems in regression  
- How to diagnose it using statistical metrics  
- How to take corrective actions before model building  

---

##  Technologies Used
- Python  
- Pandas  
- NumPy  
- Statsmodels  
- Scikit-Learn  
- Seaborn  
- Matplotlib  

---

##  How to Use This Repository
1. Clone the repository:

git clone https://github.com/Som97-Lm/Multicollinearity-Diagnostics-1.git

2. Open the notebook:
3. Run the cells step-by-step to explore multicollinearity behavior and fixes.

---

##  Future Enhancements
- Add automated VIF reporting function  
- Add feature selection suggestions based on VIF  
- Add correlation heatmap comparison before/after fixes  
- Add regularization example to show how Lasso/Ridge reduce multicollinearity impact  

---

##  Author
**Soumen Manna**  
Machine Learning & Data Science Practitioner  
Focused on building clear, practical notebooks to strengthen foundational ML concepts.

---

If you find this notebook helpful, please **star ‚≠ê the repository**!
